# lightning.pytorch==2.5.3
trainer:
  accelerator: auto
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: 16
  accumulate_grad_batches: 2
  logger:
    class_path: lightning.pytorch.loggers.CSVLogger
    init_args:
      save_dir: /workspaces/experimental-wsd/lightning_logs
      name: usas_jhu_clsp_ettin_encoder_17m
      version: null
      prefix: ''
      flush_logs_every_n_steps: 100
model:
  base_model_name: "jhu-clsp/ettin-encoder-17m"
  freeze_base_model: false
  number_transformer_encoder_layers: 0
  add_scalar_mixer: false
  scalar_mix_layer_norm: true
  transformer_encoder_hidden_dim: 512
  transformer_encoder_num_heads: 8
  batch_first: true
  learning_rate: 8.3e-05
  weight_decay: 0.01
  use_scheduler: false
  fraction_of_warm_up_steps: 0.1
  scheduler_frequency: 1
data:
  batch_size: 32
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26806239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1db0272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Annotation(raw='long', lemma='long', pos=<UniversalDepPOSTags.ADJ: 'adj'>, offset=[4, 8], token_off=[1], source=None, labels=['long%3:00:02::'], is_mwe=False, a_sub_token=False, number_labels=1, id='d000.s000.t000', overlapping_annotations=[]), Annotation(raw='been', lemma='be', pos=<UniversalDepPOSTags.VERB: 'verb'>, offset=[16, 20], token_off=[4], source=None, labels=['be%2:42:03::'], is_mwe=False, a_sub_token=False, number_labels=1, id='d000.s000.t001', overlapping_annotations=[]), Annotation(raw='reviewed', lemma='review', pos=<UniversalDepPOSTags.VERB: 'verb'>, offset=[31, 39], token_off=[7], source=None, labels=['review%2:31:00::'], is_mwe=False, a_sub_token=False, number_labels=1, id='d000.s000.t002', overlapping_annotations=[]), Annotation(raw='objectives', lemma='objective', pos=<UniversalDepPOSTags.NOUN: 'noun'>, offset=[44, 54], token_off=[9], source=None, labels=['objective%1:09:00::'], is_mwe=False, a_sub_token=False, number_labels=1, id='d000.s000.t003', overlapping_annotations=[]), Annotation(raw='benefit', lemma='benefit', pos=<UniversalDepPOSTags.NOUN: 'noun'>, offset=[63, 70], token_off=[12], source=None, labels=['benefit%1:21:00::'], is_mwe=False, a_sub_token=False, number_labels=1, id='d000.s000.t004', overlapping_annotations=[]), Annotation(raw='service', lemma='service', pos=<UniversalDepPOSTags.NOUN: 'noun'>, offset=[75, 82], token_off=[14], source=None, labels=['service%1:04:07::'], is_mwe=False, a_sub_token=False, number_labels=1, id='d000.s000.t005', overlapping_annotations=[]), Annotation(raw='program', lemma='program', pos=<UniversalDepPOSTags.NOUN: 'noun'>, offset=[83, 90], token_off=[15], source=None, labels=['program%1:09:01::'], is_mwe=False, a_sub_token=False, number_labels=1, id='d000.s000.t006', overlapping_annotations=[])]\n"
     ]
    }
   ],
   "source": [
    "import wn\n",
    "from wn.compat import sensekey\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from experimental_wsd.config import RaganatoEnglish, DATA_PROCESSING_DIR\n",
    "from experimental_wsd.wsd import wsd_sentence_generator\n",
    "from experimental_wsd.wordnet_utils import check_lexicon_exists\n",
    "from experimental_wsd.training_utils import get_prefix_suffix_special_token_indexes\n",
    "from experimental_wsd.training_utils import write_to_jsonl\n",
    "\n",
    "semcor_data_directory = RaganatoEnglish.semcor\n",
    "\n",
    "EN_LEXICON = 'omw-en:1.4'\n",
    "check_lexicon_exists(EN_LEXICON)\n",
    "ENGLISH_WN = wn.Wordnet(lexicon=EN_LEXICON, expand='')\n",
    "GET_SENSE = sensekey.sense_getter(EN_LEXICON, ENGLISH_WN)\n",
    "GET_SENSE_ID = sensekey.sense_key_getter(EN_LEXICON)\n",
    "\n",
    "for example in wsd_sentence_generator(semcor_data_directory, GET_SENSE):\n",
    "    annotation = example.annotations\n",
    "    print(example.annotations)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b9d49d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(medicine) any objective evidence of the presence of a disorder or disease'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENGLISH_WN.sense(\"omw-en-sign-14301785-n\").synset().definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78556d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sense('omw-en-try-02530167-v')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GET_SENSE(\"try%2:41:00::\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9f8cf71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'make an effort or attempt'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GET_SENSE(\"try%2:41:00::\").synset().definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa1c68e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good%3:00:01::'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GET_SENSE_ID(wn.sense(\"omw-en-good-01123148-a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85cd671b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['omw-en-at_last-00047903-r']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a.id for a in ENGLISH_WN.senses(\"at last\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcff726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw='long' lemma='long' pos=<UniversalDepPOSTags.ADJ: 'adj'> offset=[4, 8] token_off=[1] source=None labels=['long%3:00:02::'] is_mwe=False a_sub_token=False number_labels=1 id='d000.s000.t000' overlapping_annotations=[]\n",
      "['long%3:00:02::']\n",
      "Synset('omw-en-01437963-a')\n",
      "raw='been' lemma='be' pos=<UniversalDepPOSTags.VERB: 'verb'> offset=[16, 20] token_off=[4] source=None labels=['be%2:42:03::'] is_mwe=False a_sub_token=False number_labels=1 id='d000.s000.t001' overlapping_annotations=[]\n",
      "['be%2:42:03::']\n",
      "Synset('omw-en-02604760-v')\n",
      "raw='reviewed' lemma='review' pos=<UniversalDepPOSTags.VERB: 'verb'> offset=[31, 39] token_off=[7] source=None labels=['review%2:31:00::'] is_mwe=False a_sub_token=False number_labels=1 id='d000.s000.t002' overlapping_annotations=[]\n",
      "['review%2:31:00::']\n",
      "Synset('omw-en-00696189-v')\n",
      "raw='objectives' lemma='objective' pos=<UniversalDepPOSTags.NOUN: 'noun'> offset=[44, 54] token_off=[9] source=None labels=['objective%1:09:00::'] is_mwe=False a_sub_token=False number_labels=1 id='d000.s000.t003' overlapping_annotations=[]\n",
      "['objective%1:09:00::']\n",
      "Synset('omw-en-05981230-n')\n",
      "raw='benefit' lemma='benefit' pos=<UniversalDepPOSTags.NOUN: 'noun'> offset=[63, 70] token_off=[12] source=None labels=['benefit%1:21:00::'] is_mwe=False a_sub_token=False number_labels=1 id='d000.s000.t004' overlapping_annotations=[]\n",
      "['benefit%1:21:00::']\n",
      "Synset('omw-en-13296899-n')\n",
      "raw='service' lemma='service' pos=<UniversalDepPOSTags.NOUN: 'noun'> offset=[75, 82] token_off=[14] source=None labels=['service%1:04:07::'] is_mwe=False a_sub_token=False number_labels=1 id='d000.s000.t005' overlapping_annotations=[]\n",
      "['service%1:04:07::']\n",
      "Synset('omw-en-00584891-n')\n",
      "raw='program' lemma='program' pos=<UniversalDepPOSTags.NOUN: 'noun'> offset=[83, 90] token_off=[15] source=None labels=['program%1:09:01::'] is_mwe=False a_sub_token=False number_labels=1 id='d000.s000.t006' overlapping_annotations=[]\n",
      "['program%1:09:01::']\n",
      "Synset('omw-en-05899087-n')\n"
     ]
    }
   ],
   "source": [
    "for item in annotation:\n",
    "    print(item)\n",
    "    print(item.labels)\n",
    "    print(GET_SENSE(item.labels[0]).synset().)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aaa378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ec71a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
    "a_name = \"jhu-clsp/ettin-encoder-17m\"\n",
    "a_name = \"FacebookAI/roberta-base\"\n",
    "a_model = AutoModel.from_pretrained(a_name)\n",
    "a_config = AutoConfig.from_pretrained(a_name)\n",
    "a_tokenizer = AutoTokenizer.from_pretrained(a_name, add_prefix=True)\n",
    "a_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54a4916f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one of the British colonies that formed the United States'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENGLISH_WN.sense(\"omw-en-New_York-09118181-n\").synset().definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f923ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "            \"omw-en-be-02702508-v\",\n",
    "        ],\n",
    "        [\"omw-en-New_York-09119277-n\", \"omw-en-New_York-09118181-n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e57b911d",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "no such sense: a",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mError\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mENGLISH_WN\u001b[49m\u001b[43m.\u001b[49m\u001b[43msense\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ma\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/wn/_core.py:1514\u001b[39m, in \u001b[36mWordnet.sense\u001b[39m\u001b[34m(self, id)\u001b[39m\n\u001b[32m   1512\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Sense(*\u001b[38;5;28mnext\u001b[39m(iterable), _lexconf=\u001b[38;5;28mself\u001b[39m._lexconf)\n\u001b[32m   1513\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1514\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m wn.Error(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mno such sense: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mid\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mError\u001b[39m: no such sense: a"
     ]
    }
   ],
   "source": [
    "ENGLISH_WN.sense(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c84088d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sense('omw-en-Be-14631295-n'),\n",
       " Sense('omw-en-be-02604760-v'),\n",
       " Sense('omw-en-be-02616386-v'),\n",
       " Sense('omw-en-be-02655135-v'),\n",
       " Sense('omw-en-be-02603699-v'),\n",
       " Sense('omw-en-be-02749904-v'),\n",
       " Sense('omw-en-be-02664769-v'),\n",
       " Sense('omw-en-be-02620587-v'),\n",
       " Sense('omw-en-be-02445925-v'),\n",
       " Sense('omw-en-be-02697725-v'),\n",
       " Sense('omw-en-be-02268246-v'),\n",
       " Sense('omw-en-be-02614181-v'),\n",
       " Sense('omw-en-be-02744820-v'),\n",
       " Sense('omw-en-be-02702508-v')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENGLISH_WN.senses(\"be\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c3495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afb209a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the largest city in New York State and in the United States; located in southeastern New York at the mouth of the Hudson river; a major financial and cultural center'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENGLISH_WN.words(\"new york\")[0].senses()[0].synset().definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb6b0069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Hello</s>'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tokenizer.decode([0,20920,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42674672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids\n",
      "[[0, 20920, 141, 32, 47, 2], [0, 38, 524, 15983, 2], [0, 2]]\n",
      "attention_mask\n",
      "[[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(\n",
    "    \"FacebookAI/roberta-base\", add_prefix_space=True\n",
    ")\n",
    "sentence = [\"Hello how are you\", \"I am ok\", \"\"]\n",
    "tokenized_sentence = TOKENIZER(sentence)\n",
    "for key, value in tokenized_sentence.items():\n",
    "    print(key)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dde35503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids\n",
      "[0, 20920, 141, 32, 47, 2]\n",
      "attention_mask\n",
      "[1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "sentence = [\"Hello\", \"how\", \"are\", \"you\"]\n",
    "tokenized_sentence = TOKENIZER(sentence, is_split_into_words=True)\n",
    "for key, value in tokenized_sentence.items():\n",
    "    print(key)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad85c113",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtokenized_sentence\u001b[49m\u001b[43m.\u001b[49m\u001b[43mword_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:392\u001b[39m, in \u001b[36mBatchEncoding.word_ids\u001b[39m\u001b[34m(self, batch_index)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._encodings:\n\u001b[32m    388\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    389\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mword_ids() is not available when using non-fast tokenizers (e.g. instance of a `XxxTokenizerFast`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    390\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m class).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    391\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_encodings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_index\u001b[49m\u001b[43m]\u001b[49m.word_ids\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "tokenized_sentence.word_ids(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3ae2ed9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m sentence = [\u001b[33m\"\u001b[39m\u001b[33mHello how are you\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33ma Test\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m tokenized_sentence = \u001b[43ma_tokenizer\u001b[49m(sentence, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, padding=\u001b[38;5;28;01mTrue\u001b[39;00m, truncation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'a_tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "sentence = [\"Hello how are you\", \"a Test\"]\n",
    "tokenized_sentence = a_tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd09f22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [\"Hello how are you\", \"a Test\"]\n",
    "tokenized_sentence = a_tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "states = a_model(**tokenized_sentence, output_hidden_states=True).hidden_states\n",
    "len(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb6b41d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullArgSpec(args=['self', 'config', 'add_pooling_layer'], varargs=None, varkw=None, defaults=(True,), kwonlyargs=[], kwonlydefaults=None, annotations={})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "import inspect\n",
    "inspect.getfullargspec(transformers.RobertaModel.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3750a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Map: 100%|██████████| 33458/33458 [00:04<00:00, 7146.58 examples/s]\n",
      "Map: 100%|██████████| 3718/3718 [00:00<00:00, 7086.79 examples/s]\n",
      "Map: 100%|██████████| 33458/33458 [00:01<00:00, 25897.32 examples/s]\n",
      "Map: 100%|██████████| 3718/3718 [00:00<00:00, 33612.00 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import wn\n",
    "from wn.compat import sensekey\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from experimental_wsd.config import RaganatoEnglish, DATA_PROCESSING_DIR\n",
    "from experimental_wsd.wsd import wsd_sentence_generator\n",
    "from experimental_wsd.wordnet_utils import check_lexicon_exists\n",
    "from experimental_wsd.training_utils import get_prefix_suffix_special_token_indexes\n",
    "from experimental_wsd.training_utils import write_to_jsonl\n",
    "from experimental_wsd.data_processing_utils import map_token_text_and_is_content_labels, tokenize_and_align_labels\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\", add_prefix_space=True)\n",
    "alt_tokenizer = AutoTokenizer.from_pretrained(\"jhu-clsp/ettin-encoder-17m\", add_prefix_space=True)\n",
    "\n",
    "\n",
    "semcor_data_directory = RaganatoEnglish.semcor\n",
    "\n",
    "EN_LEXICON = 'omw-en:1.4'\n",
    "check_lexicon_exists(EN_LEXICON)\n",
    "ENGLISH_WN = wn.Wordnet(lexicon=EN_LEXICON, expand='')\n",
    "GET_SENSE = sensekey.sense_getter(EN_LEXICON, ENGLISH_WN)\n",
    "\n",
    "DATA_PROCESSING_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "semcor_jsonl_file_path = write_to_jsonl(wsd_sentence_generator(semcor_data_directory, GET_SENSE), DATA_PROCESSING_DIR, 'semcor', overwrite=False)\n",
    "semcor_dataset = load_dataset(\"json\", data_files=str(semcor_jsonl_file_path))\n",
    "semcor_dataset_splits = semcor_dataset['train'].train_test_split(0.1)\n",
    "\n",
    "is_content_word_dataset = semcor_dataset_splits.map(map_token_text_and_is_content_labels, remove_columns=semcor_dataset_splits['train'].column_names, batched=False)\n",
    "labelled_content_word_dataset = is_content_word_dataset.map(tokenize_and_align_labels, batched=True, fn_kwargs={\"tokenizer\": tokenizer}, remove_columns=is_content_word_dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd0b61a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTextEncoding, AutoModel\n",
    "\n",
    "\n",
    "model = AutoModelForTextEncoding.from_pretrained(\"FacebookAI/roberta-base\", add_pooling_layer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1795fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experimental_wsd.nn.token_classifier import TokenClassifier\n",
    "\n",
    "test_classifier = TokenClassifier(\"FacebookAI/roberta-base\", True, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76de060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from experimental_wsd.training_utils import AscendingSequenceLengthBatchSampler, collate_token_classification_dataset\n",
    "\n",
    "_collate_function = collate_token_classification_dataset(tokenizer)\n",
    "train_dataset = labelled_content_word_dataset['train']\n",
    "train_batch_sampler = AscendingSequenceLengthBatchSampler(train_dataset, batch_size=4, length_key='input_ids', random=True)\n",
    "\n",
    "train_dataset_loader = DataLoader(train_dataset, collate_fn=_collate_function, batch_sampler=train_batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d55782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[32m/workspaces/experimental-wsd/src/experimental_wsd/nn/token_classifier.py\u001b[39m(\u001b[92m78\u001b[39m)\u001b[36mforward\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[32m     76\u001b[39m \n",
      "\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor, word_ids: torch.Tensor):\n",
      "\u001b[32m---> 78\u001b[39m         \"\"\"\n",
      "\u001b[32m     79\u001b[39m         This type checking library might be useful \u001b[38;5;28;01min\u001b[39;00m the future:\n",
      "\u001b[32m     80\u001b[39m         https://docs.kidger.site/jaxtyping/\n",
      "\n",
      "*** NameError: name 'mask' is not defined\n",
      "*** NameError: name 'Escape' is not defined\n",
      "*** NameError: name 'Escape' is not defined\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.perf_counter()\n",
    "output = None\n",
    "for sample in train_dataset_loader:\n",
    "    test_classifier(sample['input_ids'], sample['attention_mask'], sample['word_ids'])\n",
    "    break\n",
    "    #print(sample['input_ids'].shape)\n",
    "    #input = [train_dataset[index] for index in sample]\n",
    "    #print(input)\n",
    "    #print(_collate_function(input))\n",
    "    #print(len(sample['input_ids']))\n",
    "    #break\n",
    "print(time.perf_counter() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ef889026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32, 512])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_layer = torch.nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "src = torch.rand(10, 32, 512)\n",
    "out = encoder_layer(src)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9a48ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36452b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unsqueeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4463a7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 19, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 19, 768])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "print(output.hidden_states[1].shape)\n",
    "torch.sum(torch.stack(output.hidden_states, dim=1), dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0774425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset = labelled_content_word_dataset['train'].take(11)\n",
    "sampler = AccedingSequenceLengthBatchSampler(small_dataset, 4, 'input_ids', random=True, with_replacement=False)\n",
    "for batch in sampler:\n",
    "    print(batch)\n",
    "    batch = batch_content_word_dataset(alt_tokenizer)([small_dataset[index] for index in batch])\n",
    "    print(batch['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c89c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3600380c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "batch_sampler option is mutually exclusive with batch_size, shuffle, sampler, and drop_last",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_dataset = \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabelled_content_word_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_content_word_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43malt_tokenizer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sampler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mAccedingSequenceLengthBatchSampler\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:364\u001b[39m, in \u001b[36mDataLoader.__init__\u001b[39m\u001b[34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sampler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    362\u001b[39m     \u001b[38;5;66;03m# auto_collation with custom batch_sampler\u001b[39;00m\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m batch_size != \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m shuffle \u001b[38;5;129;01mor\u001b[39;00m sampler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m drop_last:\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    365\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mbatch_sampler option is mutually exclusive \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    366\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mwith batch_size, shuffle, sampler, and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    367\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mdrop_last\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    368\u001b[39m         )\n\u001b[32m    369\u001b[39m     batch_size = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    370\u001b[39m     drop_last = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: batch_sampler option is mutually exclusive with batch_size, shuffle, sampler, and drop_last"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "11ac87a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 2, 2, 3, 2])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([1,2,3,4], dtype=torch.long)\n",
    "b = torch.tensor([2,2,3,2], dtype=torch.long)\n",
    "torch.hstack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a2e17e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a007f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2fb0cf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50281,  1359,  1048,   556,   352,   644,  1580,   368,  9814,   253,\n",
      "         16566,   273,   634,  5649,   285,  2579,  2086,  3736, 50282, 50283,\n",
      "         50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283],\n",
      "        [50281, 12238,   368, 11460,   352,   281,  2489,   247,  1918, 12594,\n",
      "          2086,  2581,   685,   581,   326,   556,   253,  4736,   273,  5520,\n",
      "          8183, 43812,   285,  1157, 17912,  1157,  2559, 18053,  3736, 50282],\n",
      "        [50281,  1737,  3434,   513,   368,  1056,   281,  2939,  1543,   273,\n",
      "           634,  2086,  3736, 50282, 50283, 50283, 50283, 50283, 50283, 50283,\n",
      "         50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283],\n",
      "        [50281,  3166,   368,  2557,   697,  5886,   281,  3777, 12125,  1796,\n",
      "          1204,  1157, 25759,  1157, 23678,  1157,   285, 48358,  1157,   285,\n",
      "           281,  5520,  3290,   285,  3453,  3736, 50282, 50283, 50283, 50283],\n",
      "        [50281, 12238,   368,   873,  2173, 16566,   323,   634,  8183,  9311,\n",
      "          3736, 50282, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283,\n",
      "         50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283],\n",
      "        [50281,  1680,   352, 10922,   841,  7342,  3736, 50282, 50283, 50283,\n",
      "         50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283,\n",
      "         50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283],\n",
      "        [50281,  1680,   352,  4067,   390, 43126,  1321,   685,   368,  1663,\n",
      "           878,  3736, 50282, 50283, 50283, 50283, 50283, 50283, 50283, 50283,\n",
      "         50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283],\n",
      "        [50281,  6272,   368,   970,   253,   954, 37265, 11993,  3082,  1157,\n",
      "          2929,  1157,  3966,    15,   964, 50282, 50283, 50283, 50283, 50283,\n",
      "         50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283],\n",
      "        [50281,  6272,   627,   643,  1157, 20182, 10924,  5609,   326,   812,\n",
      "           320, 18528,  3736, 50282, 50283, 50283, 50283, 50283, 50283, 50283,\n",
      "         50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283],\n",
      "        [50281, 14026,   634, 12046,  2584,  8183,  5373, 14659,   271,  6714,\n",
      "           273,  1959, 20890,  2208, 15078,   789,   275,   634,  4444,  3736,\n",
      "         50282, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283]])\n"
     ]
    }
   ],
   "source": [
    "for sample in train_dataset:\n",
    "    print(sample['input_ids'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64f98f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'is_content_word', 'input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_content_word_dataset['train'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0daad7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(hf_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e21dcc3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(hf_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "70fa589c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"sentence_id\":{\"dataset_id\":\"semcor\",\"document_index\":0,\"sentence_index\":0},\"text\":\"How long has it been since you reviewed the objectives of your benefit and service program ?\",\"tokens\":[{\"raw\":\"How\",\"lemma\":\"how\",\"pos\":\"adv\",\"offset\":[0,3],\"is_content_word\":false},{\"raw\":\"long\",\"lemma\":\"long\",\"pos\":\"adj\",\"offset\":[4,8],\"is_content_word\":true},{\"raw\":\"has\",\"lemma\":\"have\",\"pos\":\"verb\",\"offset\":[9,12],\"is_content_word\":false},{\"raw\":\"it\",\"lemma\":\"it\",\"pos\":\"pron\",\"offset\":[13,15],\"is_content_word\":false},{\"raw\":\"been\",\"lemma\":\"be\",\"pos\":\"verb\",\"offset\":[16,20],\"is_content_word\":true},{\"raw\":\"since\",\"lemma\":\"since\",\"pos\":\"adp\",\"offset\":[21,26],\"is_content_word\":false},{\"raw\":\"you\",\"lemma\":\"you\",\"pos\":\"pron\",\"offset\":[27,30],\"is_content_word\":false},{\"raw\":\"reviewed\",\"lemma\":\"review\",\"pos\":\"verb\",\"offset\":[31,39],\"is_content_word\":true},{\"raw\":\"the\",\"lemma\":\"the\",\"pos\":\"det\",\"offset\":[40,43],\"is_content_word\":false},{\"raw\":\"objectives\",\"lemma\":\"objective\",\"pos\":\"noun\",\"offset\":[44,54],\"is_content_word\":true},{\"raw\":\"of\",\"lemma\":\"of\",\"pos\":\"adp\",\"offset\":[55,57],\"is_content_word\":false},{\"raw\":\"your\",\"lemma\":\"you\",\"pos\":\"pron\",\"offset\":[58,62],\"is_content_word\":false},{\"raw\":\"benefit\",\"lemma\":\"benefit\",\"pos\":\"noun\",\"offset\":[63,70],\"is_content_word\":true},{\"raw\":\"and\",\"lemma\":\"and\",\"pos\":\"cconj\",\"offset\":[71,74],\"is_content_word\":false},{\"raw\":\"service\",\"lemma\":\"service\",\"pos\":\"noun\",\"offset\":[75,82],\"is_content_word\":true},{\"raw\":\"program\",\"lemma\":\"program\",\"pos\":\"noun\",\"offset\":[83,90],\"is_content_word\":true},{\"raw\":\"?\",\"lemma\":\"?\",\"pos\":\"punct\",\"offset\":[91,92],\"is_content_word\":false}],\"annotations\":[{\"raw\":\"long\",\"lemma\":\"long\",\"pos\":\"adj\",\"offset\":[4,8],\"token_off\":[1],\"source\":null,\"labels\":[\"long%3:00:02::\"],\"is_mwe\":false,\"a_sub_token\":false,\"number_labels\":1,\"id\":\"d000.s000.t000\",\"overlapping_annotations\":[]},{\"raw\":\"been\",\"lemma\":\"be\",\"pos\":\"verb\",\"offset\":[16,20],\"token_off\":[4],\"source\":null,\"labels\":[\"be%2:42:03::\"],\"is_mwe\":false,\"a_sub_token\":false,\"number_labels\":1,\"id\":\"d000.s000.t001\",\"overlapping_annotations\":[]},{\"raw\":\"reviewed\",\"lemma\":\"review\",\"pos\":\"verb\",\"offset\":[31,39],\"token_off\":[7],\"source\":null,\"labels\":[\"review%2:31:00::\"],\"is_mwe\":false,\"a_sub_token\":false,\"number_labels\":1,\"id\":\"d000.s000.t002\",\"overlapping_annotations\":[]},{\"raw\":\"objectives\",\"lemma\":\"objective\",\"pos\":\"noun\",\"offset\":[44,54],\"token_off\":[9],\"source\":null,\"labels\":[\"objective%1:09:00::\"],\"is_mwe\":false,\"a_sub_token\":false,\"number_labels\":1,\"id\":\"d000.s000.t003\",\"overlapping_annotations\":[]},{\"raw\":\"benefit\",\"lemma\":\"benefit\",\"pos\":\"noun\",\"offset\":[63,70],\"token_off\":[12],\"source\":null,\"labels\":[\"benefit%1:21:00::\"],\"is_mwe\":false,\"a_sub_token\":false,\"number_labels\":1,\"id\":\"d000.s000.t004\",\"overlapping_annotations\":[]},{\"raw\":\"service\",\"lemma\":\"service\",\"pos\":\"noun\",\"offset\":[75,82],\"token_off\":[14],\"source\":null,\"labels\":[\"service%1:04:07::\"],\"is_mwe\":false,\"a_sub_token\":false,\"number_labels\":1,\"id\":\"d000.s000.t005\",\"overlapping_annotations\":[]},{\"raw\":\"program\",\"lemma\":\"program\",\"pos\":\"noun\",\"offset\":[83,90],\"token_off\":[15],\"source\":null,\"labels\":[\"program%1:09:01::\"],\"is_mwe\":false,\"a_sub_token\":false,\"number_labels\":1,\"id\":\"d000.s000.t006\",\"overlapping_annotations\":[]}]}'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(hf_gen()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "59adda97",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'generator' object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_generator\n\u001b[32m      7\u001b[39m hf_gen = generic_wsl_sentence_to_hf_generator(wsd_sentence_generator(semcor_data_directory, GET_SENSE))\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mIterableDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhf_gen\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/datasets/iterable_dataset.py:2360\u001b[39m, in \u001b[36mIterableDataset.from_generator\u001b[39m\u001b[34m(generator, features, gen_kwargs, split)\u001b[39m\n\u001b[32m   2316\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create an Iterable Dataset from a generator.\u001b[39;00m\n\u001b[32m   2317\u001b[39m \n\u001b[32m   2318\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2356\u001b[39m \u001b[33;03m```\u001b[39;00m\n\u001b[32m   2357\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2358\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenerator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GeneratorDatasetInputStream\n\u001b[32m-> \u001b[39m\u001b[32m2360\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGeneratorDatasetInputStream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2361\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstreaming\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit\u001b[49m\n\u001b[32m   2362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/datasets/io/generator.py:29\u001b[39m, in \u001b[36mGeneratorDatasetInputStream.__init__\u001b[39m\u001b[34m(self, generator, features, cache_dir, keep_in_memory, streaming, gen_kwargs, num_proc, split, **kwargs)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     11\u001b[39m     generator: Callable,\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     **kwargs,\n\u001b[32m     20\u001b[39m ):\n\u001b[32m     21\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m     22\u001b[39m         features=features,\n\u001b[32m     23\u001b[39m         cache_dir=cache_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m         **kwargs,\n\u001b[32m     28\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     \u001b[38;5;28mself\u001b[39m.builder = \u001b[43mGenerator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/datasets/builder.py:343\u001b[39m, in \u001b[36mDatasetBuilder.__init__\u001b[39m\u001b[34m(self, cache_dir, dataset_name, config_name, hash, base_path, info, features, token, repo_id, data_files, data_dir, storage_options, writer_batch_size, **config_kwargs)\u001b[39m\n\u001b[32m    341\u001b[39m     config_kwargs[\u001b[33m\"\u001b[39m\u001b[33mdata_dir\u001b[39m\u001b[33m\"\u001b[39m] = data_dir\n\u001b[32m    342\u001b[39m \u001b[38;5;28mself\u001b[39m.config_kwargs = config_kwargs\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28mself\u001b[39m.config, \u001b[38;5;28mself\u001b[39m.config_id = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_builder_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[38;5;66;03m# prepare info: DatasetInfo are a standardized dataclass across all datasets\u001b[39;00m\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# Prefill datasetinfo\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    352\u001b[39m     \u001b[38;5;66;03m# TODO FOR PACKAGED MODULES IT IMPORTS DATA FROM src/packaged_modules which doesn't make sense\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/datasets/builder.py:604\u001b[39m, in \u001b[36mDatasetBuilder._create_builder_config\u001b[39m\u001b[34m(self, config_name, custom_features, **config_kwargs)\u001b[39m\n\u001b[32m    598\u001b[39m builder_config._resolve_data_files(\n\u001b[32m    599\u001b[39m     base_path=\u001b[38;5;28mself\u001b[39m.base_path,\n\u001b[32m    600\u001b[39m     download_config=DownloadConfig(token=\u001b[38;5;28mself\u001b[39m.token, storage_options=\u001b[38;5;28mself\u001b[39m.storage_options),\n\u001b[32m    601\u001b[39m )\n\u001b[32m    603\u001b[39m \u001b[38;5;66;03m# compute the config id that is going to be used for caching\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m config_id = \u001b[43mbuilder_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_config_id\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    608\u001b[39m is_custom = (config_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builder_configs) \u001b[38;5;129;01mand\u001b[39;00m config_id != \u001b[33m\"\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_custom:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/datasets/builder.py:187\u001b[39m, in \u001b[36mBuilderConfig.create_config_id\u001b[39m\u001b[34m(self, config_kwargs, custom_features)\u001b[39m\n\u001b[32m    185\u001b[39m             suffix = Hasher.hash(config_kwargs_to_add_to_suffix)\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         suffix = \u001b[43mHasher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhash\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs_to_add_to_suffix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m custom_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    190\u001b[39m     m = Hasher()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/datasets/fingerprint.py:188\u001b[39m, in \u001b[36mHasher.hash\u001b[39m\u001b[34m(cls, value)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhash\u001b[39m(\u001b[38;5;28mcls\u001b[39m, value: Any) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.hash_bytes(\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/datasets/utils/_dill.py:109\u001b[39m, in \u001b[36mdumps\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Pickle an object to a string.\"\"\"\u001b[39;00m\n\u001b[32m    108\u001b[39m file = BytesIO()\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m \u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m file.getvalue()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/datasets/utils/_dill.py:103\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, file)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdump\u001b[39m(obj, file):\n\u001b[32m    102\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Pickle an object to a file.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     \u001b[43mPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecurse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/dill/_dill.py:420\u001b[39m, in \u001b[36mPickler.dump\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdump\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj): \u001b[38;5;66;03m#NOTE: if settings change, need to update attributes\u001b[39;00m\n\u001b[32m    419\u001b[39m     logger.trace_setup(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[43mStockPickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/pickle.py:481\u001b[39m, in \u001b[36m_Pickler.dump\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.proto >= \u001b[32m4\u001b[39m:\n\u001b[32m    480\u001b[39m     \u001b[38;5;28mself\u001b[39m.framer.start_framing()\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[38;5;28mself\u001b[39m.write(STOP)\n\u001b[32m    483\u001b[39m \u001b[38;5;28mself\u001b[39m.framer.end_framing()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/datasets/utils/_dill.py:70\u001b[39m, in \u001b[36mPickler.save\u001b[39m\u001b[34m(self, obj, save_persistent_id)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[32m     69\u001b[39m     obj = \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33m_torchdynamo_orig_callable\u001b[39m\u001b[33m\"\u001b[39m, obj)\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[43mdill\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/dill/_dill.py:414\u001b[39m, in \u001b[36mPickler.save\u001b[39m\u001b[34m(self, obj, save_persistent_id)\u001b[39m\n\u001b[32m    412\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mCan\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: attribute lookup builtins.generator failed\u001b[39m\u001b[33m\"\u001b[39m % GeneratorType\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m \u001b[43mStockPickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/pickle.py:554\u001b[39m, in \u001b[36m_Pickler.save\u001b[39m\u001b[34m(self, obj, save_persistent_id)\u001b[39m\n\u001b[32m    552\u001b[39m f = \u001b[38;5;28mself\u001b[39m.dispatch.get(t)\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    557\u001b[39m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[32m    558\u001b[39m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/dill/_dill.py:1217\u001b[39m, in \u001b[36msave_module_dict\u001b[39m\u001b[34m(pickler, obj)\u001b[39m\n\u001b[32m   1214\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_dill(pickler, child=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m pickler._session:\n\u001b[32m   1215\u001b[39m         \u001b[38;5;66;03m# we only care about session the first pass thru\u001b[39;00m\n\u001b[32m   1216\u001b[39m         pickler._first_pass = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1217\u001b[39m     \u001b[43mStockPickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpickler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1218\u001b[39m     logger.trace(pickler, \u001b[33m\"\u001b[39m\u001b[33m# D2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1219\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/pickle.py:966\u001b[39m, in \u001b[36m_Pickler.save_dict\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mself\u001b[39m.write(MARK + DICT)\n\u001b[32m    965\u001b[39m \u001b[38;5;28mself\u001b[39m.memoize(obj)\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_batch_setitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/datasets/utils/_dill.py:83\u001b[39m, in \u001b[36mPickler._batch_setitems\u001b[39m\u001b[34m(self, items)\u001b[39m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfingerprint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Hasher\n\u001b[32m     82\u001b[39m     items = \u001b[38;5;28msorted\u001b[39m(items, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: Hasher.hash(x[\u001b[32m0\u001b[39m]))\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[43mdill\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_batch_setitems\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/pickle.py:990\u001b[39m, in \u001b[36m_Pickler._batch_setitems\u001b[39m\u001b[34m(self, items)\u001b[39m\n\u001b[32m    988\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tmp:\n\u001b[32m    989\u001b[39m         save(k)\n\u001b[32m--> \u001b[39m\u001b[32m990\u001b[39m         \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    991\u001b[39m     write(SETITEMS)\n\u001b[32m    992\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m n:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/datasets/utils/_dill.py:70\u001b[39m, in \u001b[36mPickler.save\u001b[39m\u001b[34m(self, obj, save_persistent_id)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[32m     69\u001b[39m     obj = \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33m_torchdynamo_orig_callable\u001b[39m\u001b[33m\"\u001b[39m, obj)\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[43mdill\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/dill/_dill.py:414\u001b[39m, in \u001b[36mPickler.save\u001b[39m\u001b[34m(self, obj, save_persistent_id)\u001b[39m\n\u001b[32m    412\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mCan\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: attribute lookup builtins.generator failed\u001b[39m\u001b[33m\"\u001b[39m % GeneratorType\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m \u001b[43mStockPickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/pickle.py:554\u001b[39m, in \u001b[36m_Pickler.save\u001b[39m\u001b[34m(self, obj, save_persistent_id)\u001b[39m\n\u001b[32m    552\u001b[39m f = \u001b[38;5;28mself\u001b[39m.dispatch.get(t)\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    557\u001b[39m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[32m    558\u001b[39m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/dill/_dill.py:1985\u001b[39m, in \u001b[36msave_function\u001b[39m\u001b[34m(pickler, obj)\u001b[39m\n\u001b[32m   1982\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m state_dict:\n\u001b[32m   1983\u001b[39m     state = state, state_dict\n\u001b[32m-> \u001b[39m\u001b[32m1985\u001b[39m \u001b[43m_save_with_postproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpickler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_create_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1986\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__code__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__defaults__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1987\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclosure\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostproc_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpostproc_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# Lift closure cell update to earliest function (#458)\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _postproc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/dill/_dill.py:1117\u001b[39m, in \u001b[36m_save_with_postproc\u001b[39m\u001b[34m(pickler, reduction, is_pickler_dill, obj, postproc_list)\u001b[39m\n\u001b[32m   1115\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1116\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[43mpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1118\u001b[39m \u001b[38;5;66;03m# pop None created by calling preprocessing step off stack\u001b[39;00m\n\u001b[32m   1119\u001b[39m pickler.write(POP)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/pickle.py:686\u001b[39m, in \u001b[36m_Pickler.save_reduce\u001b[39m\u001b[34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[39m\n\u001b[32m    684\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    685\u001b[39m     save(func)\n\u001b[32m--> \u001b[39m\u001b[32m686\u001b[39m     \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    687\u001b[39m     write(REDUCE)\n\u001b[32m    689\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    690\u001b[39m     \u001b[38;5;66;03m# If the object is already in the memo, this means it is\u001b[39;00m\n\u001b[32m    691\u001b[39m     \u001b[38;5;66;03m# recursive. In this case, throw away everything we put on the\u001b[39;00m\n\u001b[32m    692\u001b[39m     \u001b[38;5;66;03m# stack, and fetch the object back from the memo.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/datasets/utils/_dill.py:70\u001b[39m, in \u001b[36mPickler.save\u001b[39m\u001b[34m(self, obj, save_persistent_id)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[32m     69\u001b[39m     obj = \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33m_torchdynamo_orig_callable\u001b[39m\u001b[33m\"\u001b[39m, obj)\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[43mdill\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/dill/_dill.py:414\u001b[39m, in \u001b[36mPickler.save\u001b[39m\u001b[34m(self, obj, save_persistent_id)\u001b[39m\n\u001b[32m    412\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mCan\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: attribute lookup builtins.generator failed\u001b[39m\u001b[33m\"\u001b[39m % GeneratorType\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m \u001b[43mStockPickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/pickle.py:554\u001b[39m, in \u001b[36m_Pickler.save\u001b[39m\u001b[34m(self, obj, save_persistent_id)\u001b[39m\n\u001b[32m    552\u001b[39m f = \u001b[38;5;28mself\u001b[39m.dispatch.get(t)\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    557\u001b[39m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[32m    558\u001b[39m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/pickle.py:881\u001b[39m, in \u001b[36m_Pickler.save_tuple\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    879\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n <= \u001b[32m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.proto >= \u001b[32m2\u001b[39m:\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m obj:\n\u001b[32m--> \u001b[39m\u001b[32m881\u001b[39m         \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    882\u001b[39m     \u001b[38;5;66;03m# Subtle.  Same as in the big comment below.\u001b[39;00m\n\u001b[32m    883\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(obj) \u001b[38;5;129;01min\u001b[39;00m memo:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/datasets/utils/_dill.py:70\u001b[39m, in \u001b[36mPickler.save\u001b[39m\u001b[34m(self, obj, save_persistent_id)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj_type \u001b[38;5;129;01mis\u001b[39;00m FunctionType:\n\u001b[32m     69\u001b[39m     obj = \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33m_torchdynamo_orig_callable\u001b[39m\u001b[33m\"\u001b[39m, obj)\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[43mdill\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/dill/_dill.py:414\u001b[39m, in \u001b[36mPickler.save\u001b[39m\u001b[34m(self, obj, save_persistent_id)\u001b[39m\n\u001b[32m    412\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mCan\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: attribute lookup builtins.generator failed\u001b[39m\u001b[33m\"\u001b[39m % GeneratorType\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m \u001b[43mStockPickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/pickle.py:572\u001b[39m, in \u001b[36m_Pickler.save\u001b[39m\u001b[34m(self, obj, save_persistent_id)\u001b[39m\n\u001b[32m    570\u001b[39m reduce = \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33m__reduce_ex__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m572\u001b[39m     rv = \u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mproto\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    574\u001b[39m     reduce = \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33m__reduce__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: cannot pickle 'generator' object"
     ]
    }
   ],
   "source": [
    "def generic_wsl_sentence_to_hf_generator(wsl_generator):\n",
    "    def _hf_generator():\n",
    "        for sentence in wsl_generator:\n",
    "            yield {\"1\": \"2\"}\n",
    "    return _hf_generator\n",
    "\n",
    "hf_gen = generic_wsl_sentence_to_hf_generator(wsd_sentence_generator(semcor_data_directory, GET_SENSE))\n",
    "IterableDataset.from_generator(hf_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7dff2813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\", add_prefix_space=True)\n",
    "alt_tokenizer = AutoTokenizer.from_pretrained(\"jhu-clsp/ettin-encoder-17m\", add_prefix_space=True)\n",
    "\n",
    "prefix_suffix_tokens = get_prefix_suffix_special_token_indexes(tokenizer)\n",
    "alt_prefix_suffix_tokens = get_prefix_suffix_special_token_indexes(alt_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59161f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] form J28-6033-1.[SEP]'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tokens = [token.raw for token in sentence_data.tokens]\n",
    "content_labels = [int(token.is_content_word) for token in sentence_data.tokens]\n",
    "alt_tokenizer.decode(alt_tokenizer(sentence_tokens, is_split_into_words=True)['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f513064b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 1, 1, 1, 1, 1, 1, 2, None]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt_tokenizer(sentence_tokens, is_split_into_words=True).word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f2f152d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-100, 0, 1, 1, 1, 1, 1, 1, 1, 0, -100]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "align_labels_with_tokens([0,1,0], alt_tokenizer(sentence_tokens, is_split_into_words=True).word_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fc5746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2815ef56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]hello[SEP]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt_tokenizer.decode(alt_tokenizer(\"hello\")[0].ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9dc9ce28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = alt_tokenizer([\"Hello how are\", \"Hi\"], padding=True, truncation=True, add_special_tokens=False)\n",
    "tokens[1].special_tokens_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "faf8222f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mids\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "tokens[1].ids[0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86f023fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt_tokenizer.decode(get_prefix_suffix_special_token_indexes(alt_tokenizer)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d1b9edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizer, PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff2ab6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(tokenizer, PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5200057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_special_tokens, suffix_special_tokens = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1ac7cb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PreTrainedTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_prefix_suffix_special_token_indexes\u001b[39m(a_tokenizer: \u001b[43mPreTrainedTokenizer\u001b[49m | PreTrainedTokenizerFast) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m], \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]]:\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Finds the prefix and suffix special token ids for a given tokenizer when the \u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    tokenizer tokenizes text (this does not include padding or attention mask), e.g. \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \u001b[33;03m        tuple[list[int], list[int]]: The prefix and suffix special token ids.\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     17\u001b[39m     batch_encoding = tokenizer(\u001b[33m\"\u001b[39m\u001b[33ma\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'PreTrainedTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "def get_prefix_suffix_special_token_indexes(a_tokenizer: PreTrainedTokenizer | PreTrainedTokenizerFast) -> tuple[list[int], list[int]]:\n",
    "    \"\"\"\n",
    "    Finds the prefix and suffix special token ids for a given tokenizer when the \n",
    "    tokenizer tokenizes text (this does not include padding or attention mask), e.g. \n",
    "    for Roberta this would be `([0], [2])` whereby these ids represent the \n",
    "    token strings `([<s>], [</s>])`\n",
    "\n",
    "    These token ids are a list as some tokenizers may have 0 to many prefix and \n",
    "    suffix special tokens.\n",
    "\n",
    "    Args:\n",
    "        a_tokenizer (PreTrainedTokenizer | PreTrainedTokenizerFast): The \n",
    "            tokenizer to get the special token ids for.\n",
    "    Returns:\n",
    "        tuple[list[int], list[int]]: The prefix and suffix special token ids.\n",
    "    \"\"\"\n",
    "    batch_encoding = tokenizer(\"a\")\n",
    "    sentence_encoding = batch_encoding[0]\n",
    "    special_token_mask = sentence_encoding.special_tokens_mask\n",
    "    prefix_ids: list[int] = []\n",
    "    suffix_ids: list[int] = []\n",
    "    token_ids = sentence_encoding.ids\n",
    "    is_prefix = True\n",
    "    for token_index, token_index_value in enumerate(special_token_mask):\n",
    "        if token_index_value == 0:\n",
    "            is_prefix = False\n",
    "            continue\n",
    "        if is_prefix:\n",
    "            prefix_ids.append(token_ids[token_index])\n",
    "        else:\n",
    "            suffix_ids.append(token_ids[token_index])\n",
    "    return prefix_ids, suffix_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a50f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95c9892",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence_data in wsd_sentence_generator(semcor_data_directory, GET_SENSE):\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb0f95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 42891, 2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode([\"hello\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36536b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(sequence)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "decoded_string = tokenizer.decode([7993, 170, 11303, 1200, 2443, 1110, 3014])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "206a56dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WSLSentence(sentence_id=WSLID(dataset_id='semcor', document_index=351, sentence_index=78), text='form J28-6033-1 .', tokens=[Token(raw='form', lemma='form', pos=<UniversalDepPOSTags.NOUN: 'noun'>, offset=[0, 4], is_content_word=False), Token(raw='J28-6033-1', lemma='j28-6033-1', pos=<UniversalDepPOSTags.NOUN: 'noun'>, offset=[5, 15], is_content_word=False), Token(raw='.', lemma='.', pos=<UniversalDepPOSTags.PUNCT: 'punct'>, offset=[16, 17], is_content_word=False)], annotations=[])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3fd6af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"FacebookAI/roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cceda6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "722b485c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/experimental-wsd/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "162761ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('nO',)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline[0][1].model.dim_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971b0d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd4aafb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007a1822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.54347448e-02 -3.39185447e-01  4.97780591e-01  1.14386296e-02\n",
      "  3.01516795e+00  1.50914156e+00  7.56301343e-01  3.81979734e-01\n",
      "  1.06386626e+00  6.99571908e-01 -1.16303992e+00 -1.56474555e+00\n",
      " -7.74786532e-01 -1.46963322e+00 -1.46580505e+00 -2.19077778e+00\n",
      "  2.67899245e-01 -1.78003860e+00  8.79296362e-01  1.45203793e+00\n",
      " -7.79650331e-01 -4.49105471e-01  6.49957955e-01  5.38033366e-01\n",
      "  7.80750513e-01  2.23372981e-01  1.94223508e-01  5.83382130e-01\n",
      "  1.72171831e+00  2.02564850e-01  8.96435738e-01  1.30861902e+00\n",
      "  8.61933589e-01 -6.89156592e-01  1.84311271e+00  4.86476302e-01\n",
      "  6.72552407e-01  5.58840513e-01  1.72430229e+00 -1.96240470e-02\n",
      " -3.22009176e-01 -1.32678404e-01 -4.78284508e-02  2.48975545e-01\n",
      "  4.27249610e-01 -9.54889238e-01  1.31868333e-01 -8.84558380e-01\n",
      "  5.83423972e-01  2.59465314e-02  1.25337422e-01  1.62123454e+00\n",
      " -6.37417674e-01  5.26817262e-01 -8.17756541e-03 -5.66428840e-01\n",
      "  1.31545353e+00  5.68889976e-01 -2.64419764e-01  5.45280755e-01\n",
      "  8.30945596e-02  1.79329538e+00  9.87303793e-01  1.68988144e+00\n",
      "  1.84678644e-01 -1.01943493e+00  3.73402417e-01  1.45309246e+00\n",
      " -6.85817778e-01  1.14041662e+00 -2.96744168e-01  8.75743181e-02\n",
      " -8.22003007e-01 -1.39967954e+00 -5.09421170e-01  1.85953999e+00\n",
      " -1.31774489e-02 -1.43266773e+00  8.29085171e-01  1.02367854e+00\n",
      "  3.16972971e-01  9.87097561e-01 -1.62617341e-01 -9.25726414e-01\n",
      " -4.64426219e-01  4.00002360e-01 -8.59958470e-01  2.62202024e-01\n",
      "  2.25273281e-01  1.84719369e-01  1.08560532e-01 -2.04925701e-01\n",
      " -6.93167523e-02  1.29215503e+00 -9.75626647e-01  6.88104331e-01\n",
      "  8.39079440e-01  1.99211717e+00  8.01160216e-01  7.50412285e-01\n",
      " -1.47681773e+00  9.44496453e-01 -1.52268016e+00  1.30535531e+00\n",
      "  2.79271483e-01 -8.38865936e-01 -8.55629444e-01  1.26327083e-01\n",
      "  8.55377257e-01 -1.46884704e+00 -7.53739119e-01  1.80941534e+00\n",
      " -6.87611461e-01 -1.64887801e-01 -2.91347861e-01  2.16101304e-01\n",
      " -9.55747604e-01 -1.05569959e+00 -4.83416229e-01  9.06149030e-01\n",
      "  2.14041486e-01 -5.78146756e-01 -1.10907614e+00  1.13739252e-01\n",
      " -3.29669118e-01 -5.94218314e-01 -3.30096304e-01 -1.47930279e-01\n",
      " -3.10663849e-01 -8.27577770e-01  8.53165567e-01 -2.11888099e+00\n",
      "  6.50148451e-01 -1.16043374e-01  7.25416303e-01 -5.55672765e-01\n",
      " -5.25101840e-01 -3.48422825e-01 -5.96564174e-01  1.24913156e+00\n",
      "  9.14997637e-01 -8.33595157e-01  3.69834095e-01  5.82633615e-01\n",
      "  1.45948902e-01  5.67792594e-01  8.40240657e-01 -5.24218798e-01\n",
      "  6.25178695e-01  1.45327663e+00  3.12370330e-01 -5.19935906e-01\n",
      " -3.82227659e-01  1.43593144e+00  2.08582759e+00  7.75686860e-01\n",
      " -2.44114045e-02  2.57952571e-01  1.99615812e+00 -1.48196906e-01\n",
      "  1.04060578e+00 -4.94280197e-02 -1.03615856e+00  1.96310282e-01\n",
      "  5.80280364e-01  2.38355577e-01 -8.61705840e-01 -3.88114721e-01\n",
      " -1.90767914e-01  5.59403241e-01 -5.81691504e-01 -3.76177579e-01\n",
      "  1.34206796e+00  4.93263096e-01 -4.77636755e-01  1.20487154e+00\n",
      " -7.86084116e-01  4.69705105e-01  6.44173741e-01  8.85479093e-01\n",
      "  2.00526357e-01  1.10717368e+00 -2.21442729e-01  8.94050121e-01\n",
      " -8.78183663e-01 -8.64054918e-01 -9.59671289e-02 -9.21568334e-01\n",
      " -5.76553106e-01 -3.59822005e-01  2.66159803e-01  4.40602601e-02\n",
      "  7.91487470e-03  2.67011672e-01  1.72800869e-01  1.09827411e+00\n",
      "  2.13067964e-01 -4.60934579e-01  9.34942901e-01  1.44553334e-01\n",
      " -5.22751570e-01  1.57263827e+00  1.16868606e-02  3.38467926e-01\n",
      "  3.46571133e-02 -8.97278428e-01 -8.27198550e-02  3.46240222e-01\n",
      "  5.48257530e-02  9.69989717e-01 -2.92552799e-01 -6.92448199e-01\n",
      " -8.88405740e-01 -1.24842718e-01  1.58496237e+00 -1.13164425e+00\n",
      " -9.70878780e-01 -3.82269114e-01 -1.74451068e-01 -2.01028562e+00\n",
      "  1.00836313e+00 -1.09845066e+00  2.50536025e-01 -3.41226131e-01\n",
      " -3.22725549e-02  1.95777130e+00  1.48429751e-01  3.13164264e-01\n",
      " -4.68838125e-01 -6.16962463e-03 -4.06163037e-02  1.21671379e+00\n",
      " -2.03357720e+00 -3.36633354e-01  6.82552159e-01  1.71900630e+00\n",
      " -1.12603235e+00 -3.91458780e-01  1.07208586e+00  1.54242337e-01\n",
      " -1.28966105e+00  2.13287741e-01  2.62040913e-01  1.68289229e-01\n",
      "  4.28270429e-01  2.22980797e-01 -2.67084211e-01 -1.32379100e-01\n",
      " -9.51174617e-01 -8.03998053e-01 -4.50944930e-01 -1.77721059e+00\n",
      "  7.05168664e-01 -4.59182590e-01  3.08826476e-01  1.26990366e+00\n",
      "  6.27970025e-02 -9.46188271e-02  1.92991388e+00 -9.53572035e-01\n",
      "  2.08659753e-01 -1.28731263e+00 -2.03660905e-01 -1.37063885e+00\n",
      " -2.91723460e-01  1.37610865e+00  7.97518909e-01  1.45381149e-02\n",
      "  3.29041988e-01 -7.89136469e-01  9.36923683e-01  8.90983760e-01\n",
      "  2.98988134e-01  3.36241692e-01  2.37958767e-02  1.63913238e+00\n",
      " -5.21685898e-01 -1.81829959e-01 -8.34039867e-01  1.23298299e+00\n",
      "  2.12323725e-01 -9.41707730e-01  6.29085422e-01  1.07895768e+00\n",
      " -1.64606854e-01 -1.80895746e+00  5.59219837e-01 -1.38842463e+00\n",
      " -1.81832716e-01 -8.39229524e-01 -6.93480551e-01  1.50332260e+00\n",
      "  6.80517912e-01 -4.39228684e-01  1.97564274e-01  4.07177731e-02\n",
      "  4.89486426e-01  1.36529505e-01 -6.50384545e-01  1.10824442e+00\n",
      " -8.23902488e-01  6.38855517e-01  1.96149901e-01 -6.64402366e-01\n",
      " -5.70287585e-01  3.68284047e-01  3.23974162e-01  5.11193573e-01\n",
      "  2.89864898e-01 -2.57777721e-01 -6.40626132e-01  6.36462510e-01\n",
      " -4.39959727e-02 -2.70592362e-01 -4.20071065e-01 -8.38892817e-01\n",
      " -8.54538858e-01 -7.03389347e-01  5.67221940e-01  9.06966090e-01\n",
      "  1.69234559e-01 -2.90925473e-01  1.59667790e-01 -5.08335769e-01\n",
      "  7.27897644e-01 -4.39979509e-02 -2.03768939e-01 -7.23002791e-01\n",
      "  6.37415409e-01  9.51796293e-01 -7.37643659e-01  2.12888193e+00\n",
      "  1.03295457e+00  2.09544855e-03 -9.41953003e-01  4.51445013e-01\n",
      "  4.09512818e-01  9.90040421e-01  2.97100806e+00 -1.57357121e+00\n",
      "  4.14563447e-01  6.54774010e-01 -1.49440503e+00  7.48701215e-01\n",
      " -6.38323501e-02 -2.46431425e-01 -5.61901748e-01 -4.55644503e-02\n",
      " -1.45873070e-01  2.26663589e-01  1.26243043e+00  3.58497798e-01\n",
      "  1.30111825e+00  2.98575819e-01 -9.39074755e-01  3.80526006e-01\n",
      " -5.34181833e-01  2.63731956e-01 -1.07491009e-01 -1.10316539e+00\n",
      "  5.17861009e-01 -1.01896214e+00 -4.21221048e-01  4.19985354e-01\n",
      " -1.34400201e+00  2.82027811e-01 -1.24659121e+00  5.91760397e-01\n",
      " -1.03519118e+00 -5.31323135e-01 -2.64648527e-01  1.67068660e+00\n",
      " -3.89567524e-01  7.88103417e-02 -9.55636054e-03 -3.02058220e-01\n",
      " -1.00574183e+00 -3.39279562e-01  3.47035974e-01 -6.35368109e-01\n",
      "  5.83226562e-01  5.52155674e-01 -6.32331848e-01  8.68863642e-01\n",
      " -1.90918887e+00  2.04956079e+00 -1.98103046e+00 -7.87318528e-01\n",
      " -6.57944083e-01  5.45056611e-02 -1.06179774e+00  5.42596638e-01\n",
      " -4.80835408e-01 -6.39778316e-01 -5.67068636e-01 -2.78598696e-01\n",
      " -1.20633912e+00 -9.15576756e-01 -1.58903790e+00  3.87076974e-01\n",
      "  2.37081066e-01  5.80079556e-01  9.36501324e-01  1.81913733e+00\n",
      " -5.91077745e-01 -5.02268672e-01 -8.69817436e-01 -4.95526969e-01\n",
      " -7.95060277e-01 -1.60654441e-01  4.49151576e-01 -9.44716513e-01\n",
      "  1.25374317e+00  6.33138478e-01 -3.85296553e-01 -3.07111353e-01\n",
      " -1.36030406e-01  1.09603918e+00  9.05455291e-01 -1.92888275e-01\n",
      "  1.76643115e-02  1.01371419e+00  6.69334233e-01  7.52314329e-01\n",
      " -5.62727749e-01 -3.14834088e-01  1.65429022e-02 -6.24292390e-03\n",
      "  1.11030376e+00  1.20260799e+00 -8.20856154e-01 -1.16859925e+00\n",
      "  5.24546444e-01 -1.30966294e+00  1.08019698e+00 -7.88007140e-01\n",
      "  8.09207320e-01 -3.96837205e-01 -8.21104050e-01 -6.81173861e-01\n",
      "  1.86749995e+00 -2.29320496e-01  8.68075669e-01 -5.96710563e-01\n",
      " -1.11751175e+00 -2.03745991e-01  7.66391233e-02 -8.21944535e-01\n",
      "  7.82324374e-01 -9.12676990e-01 -9.63788271e-01 -5.81394285e-02\n",
      "  1.27190924e+00 -1.42083120e+00 -1.55743873e+00  1.47601330e+00\n",
      " -1.94544807e-01 -9.97666001e-01  1.46894598e+00 -1.06076574e+00\n",
      "  8.09201360e-01  7.05839455e-01  7.00113893e-01  6.13182902e-01\n",
      "  8.63998055e-01 -1.77715391e-01  3.56059372e-01 -2.39728615e-01\n",
      "  6.16548598e-01 -7.30158031e-01  4.38499749e-01  1.01091254e+00\n",
      " -1.14683092e+00  3.92774224e-01 -4.29025412e-01 -7.19191492e-01\n",
      " -1.13337696e-01 -1.96404502e-01  1.15176298e-01  6.61200702e-01\n",
      " -2.68171489e-01  1.35959670e-01  4.10233378e-01 -1.82625309e-01\n",
      " -1.33521020e+00 -1.71960313e-02  2.08197761e+00  1.02702498e+00\n",
      "  1.94447860e-01 -2.35442325e-01 -5.58311343e-01  4.14365202e-01\n",
      " -6.33728147e-01  1.92060187e-01 -5.86387396e-01  5.75893760e-01\n",
      "  2.36387812e-02  7.09574521e-01  1.73628524e-01  2.31992751e-01\n",
      " -4.42176551e-01 -2.92110026e-01 -6.29696131e-01  7.94008613e-01\n",
      "  7.85263002e-01  6.46332502e-01 -5.44577003e-01 -1.02823949e+00\n",
      " -3.93798500e-01  4.75066304e-01  9.88517940e-01  9.77221489e-01\n",
      "  3.55289221e-01 -2.55549669e-01 -2.90958047e-01  3.20438802e-01\n",
      " -9.33669031e-01 -1.87303975e-01 -2.45328569e+00 -2.19500279e+00\n",
      "  1.25604200e+00  5.72537899e-01  4.55065459e-01 -1.26287293e+00\n",
      "  2.97106653e-01 -1.09922528e-01  2.25548849e-01  2.60636300e-01\n",
      " -1.00601804e+00  1.61112070e-01  6.37129992e-02 -1.34559929e-01\n",
      "  5.55129759e-02 -2.13112056e-01 -5.84498167e-01  2.83008546e-01\n",
      " -1.24281824e+00 -8.89783204e-01  6.10921979e-01 -1.55035114e+00\n",
      " -9.95974123e-01 -1.64419532e+00  5.19021451e-01 -1.38631269e-01\n",
      "  1.74734902e+00 -1.11408174e+00 -6.70057416e-01  1.30870152e+00\n",
      " -8.28446627e-01  1.29889882e+00  9.05358121e-02  3.05948687e+00\n",
      "  2.68884778e-01  3.04876387e-01 -3.64968270e-01  4.83815640e-01\n",
      "  3.25839072e-01  1.60751808e+00  8.22489023e-01  8.99436712e-01\n",
      "  9.65416878e-02  2.11404347e+00 -5.39838493e-01  7.63770223e-01\n",
      " -9.81087029e-01  1.55542076e-01  8.99316907e-01 -2.72051275e-01\n",
      " -4.56189215e-01  1.44454852e-01 -4.52397764e-01  7.51030207e-01\n",
      "  6.39240682e-01 -1.75082779e+00  2.73293346e-01  6.48379624e-01\n",
      "  1.08178592e+00  7.68943727e-01 -3.86172146e-01  8.25831056e-01\n",
      " -7.31826305e-01 -6.10990465e-01 -5.87626278e-01 -2.11021185e-01\n",
      "  1.51319161e-01 -1.12770247e+00 -8.65951121e-01  1.08716178e+00\n",
      "  5.31999469e-01  2.12490869e+00 -1.04563355e+00 -7.66387939e-01\n",
      " -3.83034110e-01  6.83762372e-01 -1.22629941e+00  4.62154448e-01\n",
      " -1.51058626e+00  5.80303788e-01  1.06269467e+00  1.15174815e-01\n",
      " -8.32797825e-01 -1.10814303e-01  1.02196693e+00 -5.97744823e-01\n",
      " -4.81501162e-01  2.31554702e-01  1.04348511e-01  3.79897416e-01\n",
      "  1.85143337e-01  5.69392800e-01 -3.18716049e-01  1.12454748e+00\n",
      " -1.05309975e+00 -1.32097447e+00 -8.78306091e-01  5.95611632e-01\n",
      "  2.93503016e-01  6.44966900e-01 -8.23269606e-01  9.95744467e-01\n",
      " -9.06298697e-01  5.50189078e-01  6.40207708e-01 -1.33994997e+00\n",
      " -2.98965305e-01 -3.98328960e-01  2.41970286e-01 -2.19340056e-01\n",
      "  9.49194014e-01 -3.31834018e-01  4.31727350e-01  1.32519448e+00\n",
      " -9.13118124e-02 -2.00621217e-01  9.01641905e-01 -2.92840272e-01\n",
      "  9.20382082e-01 -1.57120153e-01  6.61256135e-01  6.61134496e-02\n",
      "  8.72046724e-02 -7.71013796e-01 -5.97609997e-01 -9.53775406e-01\n",
      "  1.42564499e+00  3.88614118e-01 -5.69351912e-01  3.03919882e-01\n",
      "  3.48383784e-01 -1.15927660e+00 -9.41497803e-01 -1.30127978e+00\n",
      " -6.52846813e-01  1.34560680e+00 -7.35808253e-01  1.53994179e+00\n",
      " -1.55272412e+00  1.26049146e-01 -1.41514540e-01 -1.23491752e+00\n",
      " -3.67291778e-01  2.06334405e-02  1.39207625e+00 -4.36331391e-01\n",
      " -9.66120005e-01  6.11294866e-01  2.47530967e-01  8.32463682e-01\n",
      " -7.14678407e-01  2.53501564e-01  8.24753165e-01 -2.13009059e-01\n",
      "  7.99079597e-01  3.36996168e-01  2.02040648e+00 -6.17134333e-01\n",
      "  3.83978218e-01 -8.72743840e-04  1.65587842e-01 -2.04777122e-01\n",
      "  3.44376475e-01 -1.54883444e-01 -1.32941628e+00  6.23377562e-02\n",
      "  1.20067024e+00  1.26935437e-01 -5.40115833e-01  1.52000439e+00\n",
      "  1.41285515e+00  1.05180472e-01  1.90472126e-01 -5.86128198e-02\n",
      " -1.08374774e+00  7.54300058e-01 -6.97490126e-02  7.03782082e-01\n",
      " -6.14192843e-01 -4.80362833e-01 -1.35653347e-01  1.32493937e+00\n",
      " -1.06066966e+00  1.20078899e-01  6.36017561e-01 -1.73234069e+00\n",
      " -5.39396286e-01  2.57017404e-01 -4.54314560e-01 -7.11557806e-01\n",
      "  7.79036283e-01 -4.50793624e-01  5.27872294e-02  5.08041263e-01\n",
      "  1.75141767e-01 -8.92909884e-01  8.42846394e-01 -1.29870355e+00\n",
      "  9.83343840e-01 -7.70705998e-01  8.04724872e-01  4.26181346e-01\n",
      "  1.30571151e+00 -1.27120769e+00  5.93279153e-02 -8.13431621e-01\n",
      "  9.55502927e-01  2.50438023e+00  8.02180767e-01 -8.08630645e-01\n",
      " -1.42979872e+00 -3.60092044e-01  6.58382833e-01  2.39210159e-01\n",
      "  3.29512268e-01  3.15412551e-01  6.52595103e-01  1.05940652e+00\n",
      " -4.11030591e-01  3.55245918e-01  3.54205310e-01  3.09926033e-01\n",
      "  1.49202153e-01 -5.73043749e-02 -1.47178876e+00  1.47011781e+00\n",
      "  5.04539609e-02  4.06872630e-01  1.04005851e-01 -5.93835674e-02\n",
      " -6.87246084e-01  3.25560659e-01 -7.22759366e-02 -1.60365832e+00\n",
      "  1.13415122e+00 -5.16298711e-01  9.13199723e-01 -6.43881917e-01\n",
      "  5.97208083e-01  2.28953528e+00  1.30354905e+00 -7.56280780e-01\n",
      " -3.77082556e-01 -6.18364811e-01  5.69760382e-01 -8.59133959e-01\n",
      " -2.48646855e+00 -6.16228342e-01 -2.30203256e-01 -1.74429989e+00]\n",
      "[ 0.12694296 -0.36168918 -0.22703621  0.688751    0.46118638  2.1579144\n",
      "  0.666156   -1.6206548   1.3390043   0.74247587  0.650614   -0.44046667\n",
      " -0.1625751   1.8272687  -0.23532493  1.0598416  -0.10979732 -0.19303474\n",
      "  1.1193998  -0.37078756 -0.79238147  0.4330049  -1.437313    0.0928211\n",
      "  0.84982586 -0.21603827 -1.058953    0.7576548   0.552347   -0.6300081\n",
      "  0.50029343  0.13031228  0.17496839 -0.04052673  0.32445544 -0.82741594\n",
      "  0.65683985 -0.17171797  0.23353304  1.1597577  -0.09539045  0.62729913\n",
      " -1.6060792  -0.48060355 -0.15877758  0.38350126 -1.260752    0.68491846\n",
      "  0.24505374  0.88369507 -1.2512864   1.5543015  -1.120282    0.6746808\n",
      "  0.42859718  1.2547905   0.19300786 -1.4093391   2.1305106   1.1748109\n",
      " -0.18710802  1.5999675   1.1584152   0.9217834  -1.0008854  -1.4350888\n",
      "  0.7372684   0.8808589  -0.5400267   0.90015674  0.93894506  0.6827984\n",
      " -1.4660723   0.33024248  0.2896789   0.60669315 -0.2651328  -0.26359168\n",
      "  1.4468569   0.566905    0.20149098  1.3000929   1.6401385  -0.25301078\n",
      "  0.8609111  -1.3889271  -0.25182158  0.10498653  0.14470772  0.62587565\n",
      " -0.4287241   1.5255079  -0.296064    1.5096153   1.5710855  -0.40466118\n",
      "  0.6540308  -2.4731364  -0.22339822 -0.4388014  -0.03002647  0.30542713\n",
      " -0.6016246   0.63598955  1.3671522  -0.76762587 -1.0312984   0.5331779\n",
      "  1.3278975   0.45488054 -0.24436723 -0.23338528  1.1322472   0.70612514\n",
      " -0.48624694 -1.4681891  -0.15684693  1.9126965   0.84013665 -0.1326266\n",
      "  1.3621526   0.37691176 -0.7708964  -0.18666641 -0.39789814  1.0876032\n",
      "  1.0182934  -1.2002705  -0.5339421   0.10583476  1.2780702  -1.9271425\n",
      " -0.1982269   1.4556785   0.7349639   0.5538005   0.9004314  -0.82406014\n",
      " -0.42692554 -0.03711001 -0.21286288 -0.16294968  1.6212376   0.6192069\n",
      " -1.0859874  -0.31248343  0.8723758  -1.2825279  -0.21326742 -0.5510865\n",
      "  0.06917589 -0.7677172  -0.5556681   1.3432287   0.6769842   0.32067052\n",
      " -0.58194613 -0.04447749  1.3599026   1.4326518   0.7193987   1.0155926\n",
      " -0.32065943  0.764353   -0.71915525  1.3846017  -0.34788734 -1.3916656\n",
      " -0.9113053  -0.09478015 -0.9352969  -0.20924197  1.0520611   0.37340075\n",
      " -0.03267331  1.1343172  -0.82814646  0.16324161  0.5182964   0.95433056\n",
      "  0.3714471   0.55017644  1.0650978  -0.739257   -0.27202496  0.35000834\n",
      "  0.11514777 -0.5232849   1.317517   -0.27310538  0.30449337  0.16592237\n",
      " -0.3777995  -1.0118005   0.4901371  -1.0564144  -0.9964736   0.20191838\n",
      " -0.13395134  0.4360741  -0.8282941  -0.0609678  -0.29798216 -0.7712977\n",
      "  0.82424504 -0.28268847  1.5034642   0.9697386  -0.09579818 -0.6748379\n",
      " -1.023776   -0.01857791 -0.45177236  0.23259246  0.42735347  0.44201356\n",
      "  0.02591295  2.0462632   0.05716337 -1.6141404   0.4928354  -1.1500106\n",
      "  1.002979    0.6530161  -2.2785432   0.9417626   0.06912941  0.3551799\n",
      " -0.9092066   0.784652    0.54871553  1.5309697  -1.4276779  -0.7910911\n",
      " -1.0096977   1.4373581  -1.809725   -0.5309717  -0.88401693  0.3210322\n",
      "  0.2712204   0.16271637 -0.4524965  -0.8069285  -0.3878098  -0.2796151\n",
      "  0.29693255 -0.02509062 -0.21483174  1.1968774  -0.5647824  -2.5446837\n",
      "  0.09746726  0.07733311  0.2258766   1.2114613  -0.5734128   0.24007733\n",
      "  0.58215374  0.5834868  -0.20955932  0.46200374 -0.3649351  -0.3232345\n",
      "  0.04784651 -0.33180356 -0.51067984 -0.16997993 -0.16532367  0.23935676\n",
      " -0.74218076 -0.4160819   0.45307356 -0.15415414  0.6536872   0.75072944\n",
      " -0.18080765 -0.4025057  -0.3927228  -0.49796683  1.5421053   0.17662844\n",
      "  0.03515924  1.1704749  -2.0846486  -1.328885   -0.86284167 -0.7456431\n",
      " -0.9182652  -0.93203     1.1497625   1.3724848  -0.3013712  -0.921294\n",
      " -0.05536953  0.47905686  0.32613033 -0.7926158  -0.72924644 -1.0317022\n",
      " -0.9554663   0.15819874 -0.22440419 -0.04836809  0.5159227   0.76538074\n",
      "  0.64048517 -0.41214257 -0.23978636 -0.68578684 -0.5306927   0.96108514\n",
      " -0.06883309  0.2699908   0.11576884  0.77533764  0.91960055 -0.72359234\n",
      "  0.32492438  0.16904359 -0.21479242 -0.53530866  0.42832208 -0.04023373\n",
      " -0.107737   -0.18005359  0.754821   -0.9137194   0.5832423   1.2106421\n",
      " -0.53916067  0.35524702 -0.63742346  0.3587312  -1.614693   -0.73766965\n",
      " -0.5420393   0.9808747  -0.13097584 -0.09081842  1.7246875  -1.0465051\n",
      "  0.1584448  -1.3315879   0.6442322  -0.38655394  0.75138766 -0.35724834\n",
      "  0.8624019   0.82051456  1.0275213   0.00898638 -0.23040435  0.16920301\n",
      " -0.788531    0.18756077  0.24395971  0.66797614 -0.95940226  0.3810725\n",
      "  2.1281886   0.47627425  0.593987    1.2671735  -0.6360145   0.5727784\n",
      " -1.1565952  -1.5796282  -1.2525284   0.6507085   0.11584583  0.47988898\n",
      "  0.5381484  -1.4563779  -0.31519288  0.6908472  -0.80829716 -1.0550588\n",
      " -0.537598   -0.2901309  -0.66525626  1.1820834  -0.77282584  0.21920979\n",
      " -0.19404747  1.0028646  -1.0494686   0.5190517   0.59386516 -0.6124303\n",
      " -0.08658651  0.6353553   0.14106107 -0.00973844 -0.18097416 -0.27139154\n",
      "  0.5418248   2.2969403  -1.4108559  -0.17557746  0.0629573   0.56326044\n",
      " -0.5862397   1.0242033   1.0303277  -2.5629823  -0.21144739  1.8743356\n",
      " -0.7201102   1.5966      0.72869015  0.54182607  0.6724231  -0.96543086\n",
      "  1.1557398  -0.8311821   0.0080754  -0.952564    0.6664189  -0.05389073\n",
      "  0.36777177 -0.02755321  0.71801215  0.15538825 -1.110082    0.2230591\n",
      "  1.3237534  -0.3177979   1.9412086  -0.58711654 -0.46873316  0.6517013\n",
      "  1.5013258   0.4135262   0.68978536 -0.6001878   0.04979328  0.29642758\n",
      "  0.330486    0.4804303   1.6805753  -0.58220685  0.8649126  -0.22205912\n",
      "  0.1682504   0.07948304 -0.75308925  0.28278765 -0.5058578   0.727214\n",
      " -0.7790586  -0.36569396  1.1469144  -1.5581006  -1.191201   -0.01751815\n",
      "  0.59195876 -1.0722481   0.03690593  0.83288133 -0.48618123  0.4981033\n",
      " -0.46244216 -0.17565271  2.1951225   0.6430682   0.78255403 -1.3945227\n",
      "  0.07330959 -0.4498412   0.70141554  0.2019371  -1.9197541   0.26402164\n",
      "  0.98166454 -0.57974267  1.539549   -0.64974296 -0.91830426 -0.34366158\n",
      "  0.47576037  0.49379328  0.27763823 -1.0369422  -0.7563615  -0.3881034\n",
      "  0.456743    0.55225503 -0.70201194 -0.0501244  -0.8116632  -0.5028291\n",
      "  0.7605769   1.6029719  -0.55267566  0.48194703 -1.8036743   0.4813671\n",
      "  0.16876613  0.83079886  0.35548592 -0.3955592   0.41080835  0.19797178\n",
      "  0.1302748  -0.7311092   0.04208259 -0.11067953  1.1229067   0.54517823\n",
      "  0.04991976  0.3711815   0.06426337 -1.0109802   1.3667824   0.28089833\n",
      " -0.735148    0.21673343 -1.1370486  -0.24246898  0.25973687 -0.19258535\n",
      " -0.44393846 -0.6837482  -0.7878943  -0.83531666 -0.77983433 -0.6034646\n",
      "  0.9600431  -2.1501517   1.8799738   0.1601775   1.3565478   0.28680885\n",
      "  0.8969659  -1.7607288  -0.23568921 -0.23572679  0.7873072   0.05394358\n",
      " -0.7904101   0.7698546   0.16009113 -0.47572842  0.37304354 -0.08775221\n",
      "  0.7679196   0.765528   -1.1801109   1.2896583  -0.41831934  0.46416506\n",
      "  0.29819167  0.7520577  -1.0579616  -1.2571625  -0.48471516  1.3940843\n",
      "  0.5109141   1.6073016  -0.0773222   0.87761986  0.43823636  0.47046116\n",
      " -0.03518479 -0.6055787  -0.38965192 -1.1474757   0.39782527 -0.8470723\n",
      " -1.279169    0.03100091 -0.38602847  1.0822958  -0.5001224   0.00557944\n",
      "  0.18165065  0.8025327   0.20593971  1.5470735  -0.11551172  0.01051308\n",
      " -1.1551684   0.45163625 -0.09930674 -0.46564713  1.4605542   0.39448565\n",
      "  0.25646794 -0.5726253  -0.56633765  0.42359868 -0.3285557   1.002219\n",
      " -0.31622544 -0.9697954  -0.19946033  0.19424115  1.1206954  -0.6234241\n",
      " -0.27415964  1.0156239   1.354914    0.25965455 -0.19253276 -0.61254954\n",
      " -0.12476589  0.11865938 -0.49525106  0.1837878  -0.47311643  0.23763406\n",
      " -1.3697227  -1.0152888   0.8242089   0.6946563  -0.23904276  0.01647741\n",
      " -0.84184575 -0.6711762  -2.2025545  -0.323361    0.14129221 -0.8463126\n",
      "  0.11135265  0.3165785  -0.28424823  0.9054212   0.60175985 -0.9803719\n",
      "  0.4560565  -0.26162687  0.5244465  -0.764959    0.24330689 -0.83247703\n",
      "  0.3950227   0.9696959   1.3297234   1.0996941  -0.33431077  1.9164433\n",
      " -0.87905633  1.8984213   0.686195   -0.5060346   0.0859646   1.0005417\n",
      "  1.0003471  -0.5034367  -0.19632465 -0.034058    0.15299776  0.6469943\n",
      "  0.05558163 -0.35166767 -1.246856    0.10150716  0.01940369 -1.3394129\n",
      " -0.7575288  -0.88462144 -0.01592653  0.50476384  2.0590456   0.18800734\n",
      " -1.1819755  -1.504497   -0.25835726 -0.59528893  0.46253604 -0.18788227\n",
      " -1.9605266   0.7118848   2.321188    0.0563156   0.33566704  1.7272147\n",
      "  0.7511957   0.29751226  1.0194222   0.3661435  -2.5056708  -0.11528277\n",
      " -0.27347076 -0.13811605  0.29283103  0.14114368 -0.20997304  1.2241865\n",
      " -1.0758766  -0.70953274 -0.24418575  0.20230135 -1.5811186  -0.1484794\n",
      "  0.37614882  0.19000262  0.12885381  2.5227244  -0.20127515  0.40877387\n",
      "  0.6457024   0.20031118 -0.19609399 -0.57750994 -0.2170924   0.17332043\n",
      " -0.62656516 -0.49984434 -0.6143984   1.0520244  -0.25822484  0.09476133\n",
      "  0.24678037 -0.66030943  1.2955494  -1.3234494   1.8477811   1.6401569\n",
      "  1.0066378  -1.6726512  -0.46912655 -0.37905076  1.2310673  -0.61521226\n",
      "  0.72778106  0.30121663 -0.3188233   0.6115829   0.3645326  -1.6912605\n",
      " -1.2365415   0.4587197  -0.6866358   1.2222819  -1.2830755  -1.7697376\n",
      "  0.72500736  1.7214851   1.0368418  -0.79684997  0.5870063  -0.1718835\n",
      " -1.0790334  -0.05159615  0.21676394 -2.4421422   1.9454278   0.38502216\n",
      "  0.35217115 -0.06028646 -1.0448151  -0.15220405 -0.12282729  0.5944729\n",
      " -0.5520554  -0.39425948  1.2687418  -0.33686748 -0.96091074 -1.1525762\n",
      " -0.5563406  -0.18766676 -0.7776353  -0.45627972 -0.36700088 -0.06702433]\n"
     ]
    }
   ],
   "source": [
    "# To do with spacy for testing is to download the roberta model from huggingface and add it to spacy\n",
    "# To run spacy in GPU mode we will need to change the base image of the Nvidia dockerfile to \n",
    "# one that contains nvcc which I think is the dev base image.\n",
    "test_sentences = [\"Hello how are you\", \"I'am well and yourself?\"]\n",
    "tokvecs = []\n",
    "vectors = None\n",
    "for doc in nlp.pipe(test_sentences):\n",
    "    print(doc._.trf_data.all_outputs[0].data[0])\n",
    "\t#vectors = doc._.trf_data.tensors[-1]\n",
    "    #tokvecs.append(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86f29634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409795a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(test_sentences[0], return_tensors='pt')\n",
    "model.eval()\n",
    "import torch\n",
    "with torch.no_grad():\n",
    "\toutput = model(**encoded_input, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "68ce3ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.2293e-01,  1.0708e-01, -3.0101e-01, -6.6282e-02,  6.7040e-01,\n",
       "         2.5819e-01,  5.1183e-01, -3.9767e-02,  7.0231e-02,  2.8814e-01,\n",
       "        -2.7704e-01, -3.2788e-01,  4.1231e-02, -6.3596e-01, -8.5969e-02,\n",
       "         3.3798e-01,  3.5524e-02, -8.0850e-02, -1.3569e-01,  9.6066e-02,\n",
       "         1.8718e-01,  3.2088e-02, -4.6662e-01,  1.8620e-01,  7.9154e-01,\n",
       "        -3.4565e-01,  5.8329e-01,  4.8632e-01,  9.4468e-01,  2.8808e-01,\n",
       "        -3.1251e-01,  1.2634e-01, -7.1679e-03, -4.0394e-01,  8.2442e-02,\n",
       "        -8.2605e-02, -1.3826e-01, -4.9883e-01,  2.1145e-01, -1.7436e-01,\n",
       "        -4.5017e-01, -4.1268e-01, -5.6027e-01,  4.2578e-01, -4.5099e-01,\n",
       "        -7.4368e-01,  1.4786e-01, -2.5236e-01, -3.7363e-01,  3.3446e-01,\n",
       "        -3.8874e-01, -1.2479e-02,  4.6802e-01, -2.2327e-02,  5.0809e-03,\n",
       "        -2.4591e-01,  2.8042e-01,  1.5542e-01, -6.0177e-01, -1.5151e-02,\n",
       "        -2.4488e-01,  3.4697e-01, -2.7597e-01,  2.4880e-01, -6.6062e-01,\n",
       "         5.0818e-01,  1.9076e-02,  1.2893e-01,  3.3541e-01,  8.3288e-02,\n",
       "         1.0522e-01,  8.3398e-01,  4.4386e-01,  5.2023e-01,  3.7185e-01,\n",
       "        -3.3537e-02,  6.8675e-02, -3.2543e-01,  3.3255e-01,  6.8707e-02,\n",
       "         2.7795e-02, -3.0642e-01,  8.3960e-02,  2.5555e-01, -4.2944e-01,\n",
       "         2.6558e-01,  1.6117e-01,  1.3320e-01, -4.9237e-01,  1.3234e-01,\n",
       "         4.0657e-01, -3.9011e-01, -3.2716e-01,  2.9395e-01, -1.2813e-01,\n",
       "        -4.3840e-01,  1.9375e-01,  4.3294e-01,  1.2263e-01,  4.2945e-02,\n",
       "        -6.4009e-02,  9.8678e-02,  3.2381e-01, -3.5912e-01,  2.8143e-02,\n",
       "        -2.6683e-01, -7.7091e-01, -1.1112e-01,  3.1448e-01, -6.0340e-01,\n",
       "        -1.4714e-03,  2.6767e-01,  1.9105e-01,  5.8057e-01, -3.2967e-02,\n",
       "        -4.9615e-01,  4.7492e-02, -4.0272e-01, -1.9135e-01,  1.4194e-01,\n",
       "         7.2727e-01, -3.5649e-02, -2.6755e-01,  1.0639e-01, -5.4961e-01,\n",
       "         3.2320e-01, -1.4002e-01, -2.9666e-01, -1.1976e-01,  1.5625e-01,\n",
       "         4.5866e-01, -1.0414e+00,  1.2215e-01, -6.7914e-01, -3.6023e-01,\n",
       "         3.8676e-01,  3.5280e-02,  4.8617e-01,  5.1097e-02,  2.5724e-01,\n",
       "         2.9133e-02,  1.6818e-01,  3.3000e-01, -2.6558e-01, -7.0707e-02,\n",
       "        -2.7154e-02,  2.7449e-01,  7.7219e-02,  7.5614e-02,  1.9067e-01,\n",
       "         2.0310e-01, -1.0436e-01,  5.3196e-01,  2.0426e-01,  2.2397e-01,\n",
       "         1.2456e-01,  3.8454e-02,  2.8559e-01,  3.8953e-01,  1.1142e-01,\n",
       "         4.9858e-01, -2.2831e-01,  5.7021e-02,  3.5843e-01, -2.3764e-01,\n",
       "        -1.2883e-01, -3.2321e-01, -3.6999e-01, -4.1053e-01, -2.6419e-01,\n",
       "        -5.0051e-01,  1.9571e-02,  7.9737e-02,  2.2008e-01, -1.5404e-01,\n",
       "        -1.4157e-02, -3.3290e-01,  5.0054e-01,  8.9690e-02,  1.7431e-01,\n",
       "         2.9276e-01, -2.0200e-01, -2.7078e-01, -3.5524e-01, -1.2422e-01,\n",
       "        -4.0762e-01, -1.1980e-01, -7.8400e-02, -1.4965e-02, -2.8364e-01,\n",
       "        -1.3294e-01, -2.3793e-01,  5.0109e-01, -6.8186e-01,  1.0964e-01,\n",
       "         1.8497e-01,  4.1004e-02, -4.1588e-01,  2.3823e-01, -2.8934e-01,\n",
       "        -2.1395e-01, -1.3023e-01,  1.1707e-02,  1.6600e-01,  3.5505e-01,\n",
       "        -1.7585e-01,  9.9750e-02,  4.4192e-01, -3.6462e-01,  9.3128e-03,\n",
       "        -3.1095e-01, -4.3206e-01, -4.6130e-01, -1.9759e-01,  2.0454e-01,\n",
       "         4.4629e-01,  3.7554e-01, -5.6898e-01, -5.5392e-02, -6.0043e-01,\n",
       "        -2.5992e-01, -3.8302e-02, -1.9810e-02,  3.4760e-01, -9.6874e-02,\n",
       "         2.7059e-01,  1.2676e-01, -4.2184e-01,  3.2309e-01, -1.6026e-01,\n",
       "         1.3064e-01, -4.6997e-02, -1.4351e-01, -2.8091e-01,  3.4300e-01,\n",
       "        -1.0292e-01,  2.7267e-01,  8.6704e-02,  6.1621e-02, -1.9189e-01,\n",
       "        -2.3689e-01,  3.5189e-01, -1.3888e-01,  6.0787e-02,  1.1939e-01,\n",
       "         3.1851e-01,  4.5769e-02, -5.9149e-02,  5.1560e-01,  1.4707e-01,\n",
       "        -3.6931e-01,  3.9369e-01,  2.7795e-01, -4.2663e-01,  8.2991e-02,\n",
       "        -8.7228e-02, -1.8400e-02, -2.4611e-03,  3.1818e-01, -5.7617e-01,\n",
       "        -1.6257e-01,  1.2830e-01,  5.5178e-02, -6.4137e-01,  3.8869e-01,\n",
       "        -6.5104e-01,  2.4847e-01, -4.3104e-01, -2.4757e-01, -4.0126e-01,\n",
       "         1.7729e-01,  1.0261e-01, -1.3312e-01,  3.5373e-01,  2.1083e-01,\n",
       "        -8.4375e-02,  3.2625e-02,  1.0892e-02, -3.4646e-01,  2.3020e-02,\n",
       "        -3.9924e-02, -5.1279e-01,  3.4393e-01, -4.0501e-01,  3.5520e-02,\n",
       "        -8.1463e-01,  1.9316e-01, -1.6422e-01, -4.2341e-01,  3.8627e-02,\n",
       "         7.4360e-01, -2.2440e-02,  3.4517e-01,  7.5940e-01, -3.3591e-01,\n",
       "         7.7541e-02,  8.6046e-02, -6.3168e-02, -1.5474e-01,  8.5809e-02,\n",
       "         1.8070e-01, -6.2814e-02,  5.4045e-01, -5.3729e-01,  4.0781e-01,\n",
       "        -4.3258e-03, -2.1228e-01,  4.2808e-01, -1.3271e-01,  1.3697e-01,\n",
       "         5.7956e-01, -4.9804e-01,  1.2137e-01, -1.4056e-01,  5.4441e-01,\n",
       "         1.3556e-01, -1.3865e-01, -2.5043e-01,  3.6712e-02, -9.1818e-02,\n",
       "         1.7830e-01,  1.4637e-01,  8.0422e-02,  3.5722e-01,  9.1303e-01,\n",
       "        -5.1239e-02,  6.9155e-01,  1.3815e-01,  2.7793e-01,  5.4387e-01,\n",
       "         1.5508e-01, -4.0408e-02,  3.6975e-01, -1.0860e-01, -8.3822e-02,\n",
       "        -2.0946e-01,  1.6383e-01,  3.4656e-01,  2.9608e-03, -4.0690e-01,\n",
       "        -7.3699e-01, -4.0306e-02,  4.2238e-01,  1.2454e-01,  1.9625e-01,\n",
       "         3.0630e-01, -1.7529e-01,  8.0156e-02,  1.2990e-01, -2.1745e-02,\n",
       "         3.4958e-01, -1.5559e-01, -9.0267e-02,  5.1936e-01, -2.2596e-01,\n",
       "         2.2908e-01, -1.3665e-01, -2.1271e-01, -3.1385e-01,  1.9729e-01,\n",
       "        -1.9229e-01,  1.2657e-01, -1.0426e-01, -3.2092e-02,  8.3017e-02,\n",
       "        -8.3663e-01, -3.5954e-01,  4.0620e-02, -2.2374e-01,  2.7758e-01,\n",
       "         1.3524e-01,  1.6845e-01,  1.3400e-01,  8.9146e-02,  6.8637e-01,\n",
       "        -4.1281e-02, -1.7884e-01,  2.5755e-01, -4.3190e-01,  3.3651e-01,\n",
       "        -2.6427e-01,  1.5333e-01,  4.8278e-01, -4.5242e-01,  2.1254e-01,\n",
       "        -1.8110e-01, -9.0972e-02, -8.7209e-02,  5.4564e-01, -1.8816e-01,\n",
       "        -2.9532e-01, -6.6900e-02, -3.0375e-01, -5.7303e-02, -9.8760e-02,\n",
       "        -5.3589e-02, -4.3365e-01, -6.9025e-01,  2.2954e-02, -3.2120e-01,\n",
       "         2.0317e-02,  3.6184e-01,  4.4471e-01,  2.8826e-01,  5.5083e-01,\n",
       "        -6.6474e-01, -1.0275e-01,  1.5999e-01, -4.9166e-01,  2.3535e-01,\n",
       "        -2.8289e-01,  7.2937e-02, -7.1342e-01,  1.4346e-01, -2.5087e-01,\n",
       "        -2.5202e-02, -2.4935e-02,  2.4064e-01,  2.0411e-01, -4.6015e-01,\n",
       "        -5.1846e-01,  5.0760e-01, -2.8011e-01, -3.2053e-01, -3.2434e-01,\n",
       "         4.0373e-01, -5.6929e-01, -1.7463e-01,  5.5867e-01,  2.6468e-01,\n",
       "        -2.5105e-02,  1.5331e-01,  3.4553e-01, -1.3178e-03, -3.0003e-01,\n",
       "         3.5458e-01, -3.9002e-02, -3.9639e-01, -1.2816e-01, -3.2824e-03,\n",
       "         3.3990e-01, -3.5151e-01,  1.0692e-01, -3.5829e-01,  3.3329e-01,\n",
       "        -2.7397e-01, -1.2872e-01, -4.8858e-02,  5.7796e-01,  2.8175e-01,\n",
       "        -2.6369e-01, -1.1778e-01,  1.2810e-01,  4.9862e-01,  2.8674e-01,\n",
       "        -2.4438e-01, -1.0055e-01,  1.0635e-01,  1.1071e-01, -4.3812e-01,\n",
       "         2.7999e-01,  2.0958e-01, -2.9732e-01, -5.5807e-01,  5.8631e-02,\n",
       "         1.1699e-01,  1.4921e-01, -1.9810e-01, -5.7626e-01, -1.6141e-01,\n",
       "         1.7340e-02,  5.6747e-01, -1.8330e-02, -4.7440e-01, -3.9387e-01,\n",
       "         1.3156e-01,  1.5669e-01, -1.7078e-01,  8.1889e-02, -3.8236e-01,\n",
       "         1.0422e-01, -3.1638e-01, -1.8235e-01,  9.9452e-02,  4.3527e-01,\n",
       "         4.6649e-01,  2.6704e-02,  2.0552e-01,  5.4092e-01,  1.3175e-01,\n",
       "        -4.6138e-01,  1.5571e-01,  3.1753e-02,  1.9474e-01, -1.7827e-01,\n",
       "         3.6366e-01, -2.9318e-02, -5.6282e-01, -5.8358e-02,  3.1230e-01,\n",
       "         5.3297e-01, -2.7868e-01, -1.7699e-01, -2.6102e-01,  2.7824e-01,\n",
       "         2.1387e-01,  3.7959e-01, -2.7629e-01,  2.0611e-01, -2.7750e-01,\n",
       "        -3.9108e-02,  9.8000e-03,  1.1758e-02,  3.4212e-01, -1.7798e-01,\n",
       "         5.3260e-01, -7.3656e-01,  4.1862e-01, -2.9350e-01,  4.0612e-02,\n",
       "         1.2699e-01,  5.1053e-01, -7.1037e-02, -2.1489e-01,  1.1705e-01,\n",
       "        -3.6269e-01,  2.5397e-01, -2.2647e-01, -5.2403e-01, -7.7772e-01,\n",
       "        -4.2517e-01, -3.7044e-01, -3.0823e-01,  4.5356e-01,  8.5934e-02,\n",
       "         1.5022e-01,  1.7886e-01, -1.8075e-01, -5.5286e-01,  6.2115e-02,\n",
       "        -6.2040e-02,  9.2823e-03, -3.9066e-02,  2.0470e-01,  3.3585e-01,\n",
       "         1.1396e-01,  3.4915e-01,  4.2310e-01,  1.3306e-01,  1.8295e-01,\n",
       "         2.4890e-01, -4.1504e-01, -2.1934e-01, -1.5974e-01,  1.5763e-01,\n",
       "        -3.3757e-01, -1.9356e-01, -3.8996e-01, -4.1321e-01, -5.7075e-01,\n",
       "        -2.6203e-01,  7.0026e-01,  4.3806e-03, -4.4237e-01, -5.3138e-01,\n",
       "         5.6290e-01, -3.6533e-01,  2.5923e-01, -5.3325e-01, -2.1181e-01,\n",
       "        -1.0138e-01,  3.0048e-01, -2.2450e-01, -3.0746e-01, -5.4548e-02,\n",
       "        -3.3354e-01, -1.7812e-01,  4.3332e-02,  3.1478e-01, -7.3737e-02,\n",
       "        -2.6128e-01, -4.0291e-01,  2.2433e-01,  2.8046e-01,  2.5083e-01,\n",
       "        -3.4058e-01,  3.6990e-01,  4.8152e-01,  1.4000e+00, -6.0958e-01,\n",
       "         1.5519e-01,  8.6298e-02, -7.0951e-02,  4.4223e-01,  6.0825e-02,\n",
       "        -1.2827e-01,  1.1660e-02, -3.3164e-01,  1.1056e-01,  1.6792e-02,\n",
       "         5.2535e-01,  1.1247e-01,  6.2660e-02, -1.7953e-01,  2.2737e-01,\n",
       "         3.9276e-01, -2.8657e-01, -2.7028e-03,  3.4760e-03, -1.4011e-02,\n",
       "        -8.8516e-02,  3.4757e-01,  3.8082e-01,  2.2417e-01,  1.9197e-02,\n",
       "        -1.6643e-01, -3.0848e-02,  3.5057e-01, -5.5911e-01, -9.0536e-02,\n",
       "        -7.2045e-01, -6.5695e-02, -2.0849e-01,  4.1119e-03,  8.6603e-02,\n",
       "         1.5768e-01, -8.2717e-02,  5.6597e-02,  4.2949e-01,  3.4413e-01,\n",
       "        -4.6713e-01, -7.5609e-02, -4.6147e-02,  3.9429e-01, -3.5633e-01,\n",
       "        -5.9797e-01,  2.7543e-01,  3.9245e-01, -3.8550e-01, -3.2908e-01,\n",
       "         2.0736e-01, -5.7083e-01, -4.6368e-01, -1.6804e-01, -9.1278e-02,\n",
       "        -3.1272e-02,  5.2340e-01, -2.3879e-01,  6.1592e-01,  1.3533e-01,\n",
       "         5.0656e-02, -3.4626e-02, -1.8953e-01, -3.5833e-01, -6.0322e-02,\n",
       "         9.6614e-02, -4.6249e-01,  3.8442e-01, -2.8653e-01, -1.9916e-01,\n",
       "        -1.2826e-01,  2.4482e-01,  5.3497e-01,  7.2728e-01, -6.1714e-02,\n",
       "        -2.0469e-01,  2.1590e-01,  2.7184e-01,  4.2464e-01,  1.5602e-01,\n",
       "         2.3657e-01,  6.0873e-01, -4.1409e-01, -1.8200e-01,  6.9700e-01,\n",
       "        -6.0124e-02, -7.1519e-02,  2.2453e-01,  3.4352e-02, -2.0607e-01,\n",
       "        -7.8736e-02, -1.6587e-01, -3.6131e-01,  5.1068e-01, -2.2987e-01,\n",
       "        -9.2795e-02, -1.7290e-02,  1.7762e-01,  4.7890e-01, -3.6634e-01,\n",
       "        -1.4517e-01,  4.8381e-01,  4.1393e-02,  4.2949e-01,  9.3347e-01,\n",
       "        -1.9241e-02, -1.4904e-01,  1.5192e-01, -3.2368e-01,  1.3212e-01,\n",
       "         6.5595e-01, -2.1897e-01, -4.9357e-01, -5.4529e-01, -1.3878e-01,\n",
       "         3.5425e-01,  8.5826e-01, -3.0117e-01, -1.9248e-01,  3.8415e-02,\n",
       "        -3.9643e-02,  1.0861e-01, -4.2797e-01,  1.3022e-01, -5.6850e-01,\n",
       "         4.4208e-01,  6.7816e-01,  2.8617e-01, -2.5795e-01, -1.3417e-01,\n",
       "         2.3101e-01,  5.7291e-02,  2.5456e-01, -2.5514e-01,  2.2042e-02,\n",
       "        -4.7040e-01,  2.0938e-02, -1.9305e-01,  1.4444e-01, -2.9956e-01,\n",
       "        -4.7201e-01, -1.0047e-01,  4.3595e-01, -4.6149e-01,  7.6324e-01,\n",
       "         8.4877e-01, -1.1007e-01, -3.6356e-01,  1.0746e-01,  8.1125e-02,\n",
       "        -5.4010e-02,  3.8100e-01,  3.7131e-01, -1.3990e-01,  5.2600e-01,\n",
       "         9.8548e-02, -2.6569e-01, -2.3690e-01,  3.2464e-01, -2.8685e-01,\n",
       "         6.0205e-03, -3.4943e-01, -7.6407e-02,  4.3438e-01, -4.4239e-02,\n",
       "        -8.8339e-02,  4.9908e-01,  5.0946e-01,  4.5087e-01, -1.3056e-01,\n",
       "         2.0290e-01, -9.3747e-02,  4.0329e-01, -5.9201e-01, -2.1182e-01,\n",
       "         3.5220e-02, -3.3721e-01,  2.6028e-01])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.hidden_states[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2cd3310f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 31414,   141,    32,    47,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dce767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GET_SENSE(\"editorial%1:10:00::\").synset().relations()\n",
    "GET_SENSE(\"enterprise%1:04:00::\").synset().definition()\n",
    "ENGLISH_WN.words(\"enterprise\", pos=\"n\")[0].synsets()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experimental-wsd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
